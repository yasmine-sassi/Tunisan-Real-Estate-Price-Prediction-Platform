{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from http.client import RemoteDisconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_path = [\n",
    "    \"Immobilier\", \n",
    "    \"ImmoNeuf/Immobilier%20Neuf\"\n",
    "]\n",
    "base_url = \"https://www.tayara.tn/ads/c/{}/?page={}\"\n",
    "\n",
    "def get_all_soup():\n",
    "    soups = []\n",
    "    for category in categories_path:\n",
    "        for page in range(1, 150):  # Limiter à 5 pages pour l'exemple\n",
    "            url = base_url.format(category, page)\n",
    "            # print(url)\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            soups.append(soup)\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permet de retourner tous les liens de chaque immobilier\n",
    "# vs pouvez inspecter https://www.tayara.tn/item/66eae8a467b755ba922a2a58/Immobilier%20Neuf/Ariana/Ghazela/Appartement_en_S2_de_12880_m_A41_au_4me_tage/\n",
    "def get_all_links(soup):\n",
    "    property_links = []\n",
    "    for article in soup.find_all('article', class_=\"mx-0\"):\n",
    "        link = article.find('a')['href']\n",
    "        if '/item/' in link:\n",
    "            full_url = \"https://www.tayara.tn\" + link\n",
    "            property_links.append(full_url)\n",
    "    return property_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def _normalize_transaction(val: str):\n",
    "    if not val:\n",
    "        return None\n",
    "    v = str(val).strip().lower()\n",
    "    if \"louer\" in v or \"location\" in v or \"à louer\" in v:\n",
    "        return \"Location\"\n",
    "    if \"vendre\" in v or \"vente\" in v or \"à vendre\" in v:\n",
    "        return \"Vente\"\n",
    "    return str(val).strip()\n",
    "\n",
    "def _int_or_none(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (int, float)):\n",
    "        return int(x)\n",
    "    s = str(x)\n",
    "    m = re.search(r\"\\d+\", s)\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def _parse_city_region_from_url(url: str):\n",
    "    try:\n",
    "        parts = [p for p in url.strip('/').split('/') if p]\n",
    "        if 'item' in parts:\n",
    "            i = parts.index('item')\n",
    "            governorate = parts[i+2] if len(parts) > i+2 else None\n",
    "            delegation = parts[i+3] if len(parts) > i+3 else None\n",
    "            city = governorate.replace('-', ' ').title() if governorate else None\n",
    "            region = delegation.replace('-', ' ').title() if delegation else None\n",
    "            return city, region\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def crawl_property_page(url: str):\n",
    "    resp = requests.get(url, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    item_info = {\n",
    "        'link': url,\n",
    "        'title': None,\n",
    "        'price': None,\n",
    "        'transaction': None,\n",
    "        'city': None,\n",
    "        'region': None,\n",
    "        'description': None,\n",
    "        'surface': None,\n",
    "        'bathrooms': None,\n",
    "        'rooms': None,\n",
    "    }\n",
    "\n",
    "    # Try to parse Next.js JSON: look for any application/json script containing adDetails\n",
    "    ad_details = None\n",
    "    ad_params = None\n",
    "    try:\n",
    "        for script in soup.find_all('script', attrs={'type': 'application/json'}):\n",
    "            txt = script.string or script.get_text() or ''\n",
    "            if 'adDetails' not in txt:\n",
    "                continue\n",
    "            data = json.loads(txt)\n",
    "            d = data\n",
    "            for key in ('props', 'pageProps'):\n",
    "                d = d.get(key) if isinstance(d, dict) else None\n",
    "                if d is None:\n",
    "                    break\n",
    "            if d and isinstance(d, dict) and 'adDetails' in d:\n",
    "                ad_details = d.get('adDetails')\n",
    "                ap = ad_details.get('adParams', []) if isinstance(ad_details, dict) else []\n",
    "                # Ensure list of dicts\n",
    "                ad_params = ap if isinstance(ap, list) else []\n",
    "                break\n",
    "    except Exception:\n",
    "        ad_details = None\n",
    "        ad_params = None\n",
    "\n",
    "    # Fill from JSON if available\n",
    "    if isinstance(ad_details, dict):\n",
    "        item_info['title'] = ad_details.get('title') or item_info['title']\n",
    "        item_info['description'] = ad_details.get('description') or item_info['description']\n",
    "        item_info['price'] = _int_or_none(ad_details.get('price')) or item_info['price']\n",
    "        loc = ad_details.get('location') or {}\n",
    "        gov = (loc.get('governorate') or '').strip()\n",
    "        delg = (loc.get('delegation') or '').strip()\n",
    "        item_info['city'] = gov or item_info['city']\n",
    "        item_info['region'] = delg or item_info['region']\n",
    "\n",
    "        # Map params\n",
    "        def get_param(label_variants):\n",
    "            if not isinstance(ad_params, list):\n",
    "                return None\n",
    "            for p in ad_params:\n",
    "                lbl = (p.get('label') or '').strip().lower()\n",
    "                val = p.get('value')\n",
    "                for lv in label_variants:\n",
    "                    if lbl == lv:\n",
    "                        return val\n",
    "                for lv in label_variants:\n",
    "                    if lv in lbl:\n",
    "                        return val\n",
    "            return None\n",
    "\n",
    "        item_info['transaction'] = _normalize_transaction(get_param([\n",
    "            'type de transaction','transaction','type'\n",
    "        ])) or item_info['transaction']\n",
    "        item_info['surface'] = _int_or_none(get_param(['superficie','surface'])) or item_info['surface']\n",
    "        item_info['bathrooms'] = _int_or_none(get_param(['salles de bains','salle de bain','sdb'])) or item_info['bathrooms']\n",
    "        item_info['rooms'] = _int_or_none(get_param(['chambres','chambre','pièces','pieces'])) or item_info['rooms']\n",
    "\n",
    "    # Fallbacks from HTML\n",
    "    if item_info['title'] is None:\n",
    "        h1 = soup.find('h1')\n",
    "        item_info['title'] = h1.get_text(strip=True) if h1 else None\n",
    "    if item_info['price'] is None:\n",
    "        price_data = soup.find('data')\n",
    "        if price_data and price_data.has_attr('value'):\n",
    "            item_info['price'] = _int_or_none(price_data['value'])\n",
    "        else:\n",
    "            span_price = soup.find('span', class_='mr-1')\n",
    "            item_info['price'] = _int_or_none(span_price.get_text()) if span_price else None\n",
    "    if item_info['description'] is None:\n",
    "        desc_h2 = soup.find('h2', string=lambda s: isinstance(s, str) and 'Description' in s)\n",
    "        if desc_h2:\n",
    "            desc_p = desc_h2.find_next('p')\n",
    "            item_info['description'] = desc_p.get_text(\" \", strip=True) if desc_p else None\n",
    "\n",
    "    # Criteria list\n",
    "    def html_criteria():\n",
    "        crit_h2 = soup.find('h2', string=lambda s: isinstance(s, str) and 'Critères' in s)\n",
    "        if not crit_h2:\n",
    "            return\n",
    "        ul = crit_h2.find_next('ul')\n",
    "        if not ul:\n",
    "            return\n",
    "        for li in ul.find_all('li'):\n",
    "            container = li.find('span', class_=lambda c: isinstance(c, str) and 'flex' in c and 'flex-col' in c)\n",
    "            if not container:\n",
    "                continue\n",
    "            children = container.find_all('span', recursive=False)\n",
    "            if len(children) < 2:\n",
    "                continue\n",
    "            label_text = children[0].get_text(strip=True).lower()\n",
    "            value_text = children[1].get_text(strip=True)\n",
    "            if 'type de transaction' in label_text or label_text in ('transaction','type'):\n",
    "                item_info['transaction'] = _normalize_transaction(value_text)\n",
    "            elif 'superficie' in label_text or 'surface' in label_text:\n",
    "                item_info['surface'] = _int_or_none(value_text)\n",
    "            elif 'salles de bains' in label_text or 'salle de bain' in label_text or 'sdb' in label_text:\n",
    "                item_info['bathrooms'] = _int_or_none(value_text)\n",
    "            elif 'chambres' in label_text or 'chambre' in label_text or 'pièces' in label_text or 'pieces' in label_text:\n",
    "                item_info['rooms'] = _int_or_none(value_text)\n",
    "    html_criteria()\n",
    "\n",
    "    if item_info['rooms'] is None and item_info['title']:\n",
    "        m = re.search(r\"\\bS\\s*\\+\\s*(\\d)\\b\", item_info['title'], re.IGNORECASE)\n",
    "        if m:\n",
    "            item_info['rooms'] = int(m.group(1))\n",
    "\n",
    "    if not item_info['city'] or not item_info['region']:\n",
    "        city_url, region_url = _parse_city_region_from_url(url)\n",
    "        item_info['city'] = item_info['city'] or city_url\n",
    "        item_info['region'] = item_info['region'] or region_url\n",
    "\n",
    "    return item_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_links = []\n",
    "for soup in get_all_soup():\n",
    "    property_link = get_all_links(soup)\n",
    "    property_links.extend(property_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename=\"immobiliers.csv\"):\n",
    "    if not data:\n",
    "        print(\"Aucune donnée à sauvegarder.\")\n",
    "        return\n",
    "\n",
    "    # Define the columns you want in order\n",
    "    fieldnames = ['link', 'title', 'price', 'transaction', 'city', 'region', \n",
    "                  'description', 'surface', 'bathrooms', 'rooms']\n",
    "\n",
    "    try:\n",
    "        with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames, extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            for row in data:\n",
    "                if row:  # Skip None entries\n",
    "                    writer.writerow(row)\n",
    "        print(f\"Données sauvegardées dans {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'enregistrement : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://www.tayara.tn/item/terrains-et-fermes/ben-arous/borj-cedria/terrain-de-500-m-borj-cedria/675ac8a4b5e4ab395e78d5e2/: ('Connection aborted.', ConnectionResetError(10054, 'Une connexion existante a dû être fermée par l’hôte distant', None, 10054, None))\n",
      "Error scraping https://www.tayara.tn/item/terrains-et-fermes/sfax/route-el-afrane/-vendre-terrain-sfax/694d2c2ccd04d08be750d17a/: HTTPSConnectionPool(host='www.tayara.tn', port=443): Read timed out. (read timeout=20)\n",
      "Error scraping https://www.tayara.tn/item/appartements/tunis/lac-2/a-louer-un-appartement-en-s3-au-lac-2/6945237f8914daae519deb77/: HTTPSConnectionPool(host='www.tayara.tn', port=443): Read timed out. (read timeout=20)\n",
      "Données sauvegardées dans final_scrapped_immobiliers.csv\n"
     ]
    }
   ],
   "source": [
    "# Scrape data\n",
    "data = []\n",
    "for link in property_links:\n",
    "    try:\n",
    "        property_data = crawl_property_page(link)\n",
    "        if property_data:  # Only add if not None\n",
    "            data.append(property_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {link}: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "save_to_csv(data, \"final_scrapped_immobiliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'DUPLEX S2 MEUBLE A BOUKORNINE', 'price': 700, 'transaction': 'Location', 'city': 'Ben Arous', 'region': 'Ezzahra', 'description': 'nous mettons pour la location un duplex s+2 meublé pour longue durée situé à proximité les commodités à boukornine.\\n\\n700d/mois\\n\\n☎:      98 176 369', 'surface': 100, 'bathrooms': 1, 'rooms': 3, 'link': 'https://www.tayara.tn/item/appartements/ben-arous/ezzahra/duplex-s2-meuble-a-boukornine/694e8cd48914daae51a1dc1d/'}\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity test for one listing (optional)\n",
    "TEST_URL = \"https://www.tayara.tn/item/appartements/ben-arous/ezzahra/duplex-s2-meuble-a-boukornine/694e8cd48914daae51a1dc1d/\"\n",
    "res = crawl_property_page(TEST_URL)\n",
    "print({k: res.get(k) for k in [\"title\",\"price\",\"transaction\",\"city\",\"region\",\"description\",\"surface\",\"bathrooms\",\"rooms\",\"link\"]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
